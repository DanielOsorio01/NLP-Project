{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgo0H3ByuEJk"
      },
      "source": [
        "# Translation model Inga - Spanish\n",
        "\n",
        "In this notebook we are going to create a transformer that uses an encoder-decoder to translate from Inga to Spanish. We are following a hugging face tutorial on translation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ7tQ4ihkVA2"
      },
      "source": [
        "## Preparing and understanding the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn2wFzA6kjdQ"
      },
      "source": [
        "### Creating the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQkhKTTAu8GY"
      },
      "source": [
        "First of all we need to import the necessary libraries to manipulate the data and load the translated sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNx0la85vhNy"
      },
      "source": [
        "Read the .csv file with the translated sentences and split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcMuKBX7vl8B",
        "outputId": "ea3d3170-a881-4844-d810-ae89b121fb0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8201 entries, 0 to 8200\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   inga     8201 non-null   object\n",
            " 1   espanol  8201 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 128.3+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data\\BIBLIA_DATASET_INGA.csv', sep= ',',header=0)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9eWpbuQOz_m",
        "outputId": "4b250803-016e-4063-88b8-fd3c9a9edc15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['inga', 'espanol'], dtype='object')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jS6f5ZLr2fgd",
        "outputId": "e8b4663f-1ee7-4b12-8694-e41cce49b48c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-aebe64de-65ba-4b5c-ae3a-475e79eb92f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inga</th>\n",
              "      <th>espanol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1793</th>\n",
              "      <td>IAIA JESUSMANDA  ALLI WILLAITA  SAN LUCASMI WI...</td>\n",
              "      <td>LUCAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5705</th>\n",
              "      <td>7 Chiuramandaka Santiagotasi  kawarirka. Nispa...</td>\n",
              "      <td>7 Luego apareció a Jacobo y después a todos lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4045</th>\n",
              "      <td>5 Chasa uiaspaka tukuikuna suglla iuiaimi tuku...</td>\n",
              "      <td>5 Esta propuesta agradó a toda la multitud; y ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8006</th>\n",
              "      <td>8 Maikanpas  kai alpapi kaugsanakug kikinpa su...</td>\n",
              "      <td>8 Y le adorarán todos los habitantes sobre la ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>62 Chasa uiaspaka iaia sasirduti saia rispa Je...</td>\n",
              "      <td>62 Se levantó el sumo sacerdote y le dijo: — ¿...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aebe64de-65ba-4b5c-ae3a-475e79eb92f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aebe64de-65ba-4b5c-ae3a-475e79eb92f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aebe64de-65ba-4b5c-ae3a-475e79eb92f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7cc54eb4-7cb0-405b-85ef-4c642f27c54b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7cc54eb4-7cb0-405b-85ef-4c642f27c54b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7cc54eb4-7cb0-405b-85ef-4c642f27c54b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                   inga  \\\n",
              "1793  IAIA JESUSMANDA  ALLI WILLAITA  SAN LUCASMI WI...   \n",
              "5705  7 Chiuramandaka Santiagotasi  kawarirka. Nispa...   \n",
              "4045  5 Chasa uiaspaka tukuikuna suglla iuiaimi tuku...   \n",
              "8006  8 Maikanpas  kai alpapi kaugsanakug kikinpa su...   \n",
              "998   62 Chasa uiaspaka iaia sasirduti saia rispa Je...   \n",
              "\n",
              "                                                espanol  \n",
              "1793                                              LUCAS  \n",
              "5705  7 Luego apareció a Jacobo y después a todos lo...  \n",
              "4045  5 Esta propuesta agradó a toda la multitud; y ...  \n",
              "8006  8 Y le adorarán todos los habitantes sobre la ...  \n",
              "998   62 Se levantó el sumo sacerdote y le dijo: — ¿...  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twbdz7QXkmHN"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdEYdFtpKWKM"
      },
      "source": [
        "The tokenization function we will implement will only divide by words, remove special characters and lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqfD03A-Kv3e"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "def tokenization(text):\n",
        "  # Leave punctuation, INCLUDES ; . * ? ¿\n",
        "  list_words = text_to_word_sequence(text, filters='!\"#$%&()+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "  return list_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjEl-ibgdRqJ",
        "outputId": "99b314b9-8a8d-4cc6-9004-ef9cf1d9100c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8201 entries, 0 to 8200\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   source  8201 non-null   object\n",
            " 1   target  8201 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 128.3+ KB\n"
          ]
        }
      ],
      "source": [
        "tokenized_inb = []\n",
        "tokenized_es = []\n",
        "\n",
        "\n",
        "for i in range(0, len(df['inga'].values)):\n",
        "    # Limpieza de caracteres raros\n",
        "    if \",\" in df.iloc[i]['inga']:\n",
        "        print(i, df.iloc[i]['inga'])\n",
        "        break\n",
        "    procesado = tokenization(df.iloc[i]['inga'])\n",
        "    tokenized_inb.append(' '.join(procesado))\n",
        "\n",
        "for i in range(0, len(df['espanol'].values)):\n",
        "    # Limpieza de caracteres raros\n",
        "    if \",\" in df.iloc[i]['espanol']:\n",
        "        print(i, df.iloc[i]['espanol'])\n",
        "        break\n",
        "    procesado = tokenization(df.iloc[i]['espanol'])\n",
        "    tokenized_es.append('<bos> '+' '.join(procesado) + ' <eos>')\n",
        "\n",
        "tokenized_df = pd.DataFrame(list(zip(tokenized_inb, tokenized_es)),\n",
        "               columns =['source', 'target'])\n",
        "\n",
        "tokenized_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKgBnPWi-Tzm"
      },
      "source": [
        "Al parecer el nuevo testamento no tiene comas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzE-ny-V3QJI",
        "outputId": "70c9f338-7318-4456-ed44-3e1da4aec7a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36 Kamkunapa umatapas *mana kawag churangichi; kamkuna manima pudingapa kangichichu ñi sug agcha iuraiachingapa u ianaiachingapa.\n",
            "36 No jurarás ni por tu cabeza porque no puedes hacer que un cabello sea ni blanco ni negro.\n",
            "36 kamkunapa umatapas *mana kawag churangichi kamkuna manima pudingapa kangichichu ñi sug agcha iuraiachingapa u ianaiachingapa\n",
            "<bos> 36 no jurarás ni por tu cabeza porque no puedes hacer que un cabello sea ni blanco ni negro <eos>\n"
          ]
        }
      ],
      "source": [
        "print(df['inga'][131])\n",
        "print(df['espanol'][131])\n",
        "print(tokenized_df['source'][131])\n",
        "print(tokenized_df['target'][131])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPZKDQ9Jhd8c"
      },
      "source": [
        "When calculating the sizes of the vocalubary for the input (inga) and output (spanish) language we can see that both have similar sized, but inga has a few more (exactly 274 more words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BloY_Ihhdok",
        "outputId": "f2fbb06a-37aa-4ccf-c404-2c960f975bc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Vocabulary Size: 18659\n",
            "Output Vocabulary Size: 11816\n"
          ]
        }
      ],
      "source": [
        "# Tokenizer for input language (inga)\n",
        "input_tokenizer = Tokenizer(oov_token=\"<unk>\", filters='\"#$%&()+-/=@[\\]^_`{|}~')\n",
        "input_tokenizer.fit_on_texts(tokenized_inb)\n",
        "input_tokenizer.word_index[\"<pad>\"] = 0\n",
        "input_tokenizer.index_word[0] = \"<pad>\"\n",
        "\n",
        "\n",
        "\n",
        "# Tokenizer for output language (spanish)\n",
        "output_tokenizer = Tokenizer(oov_token=\"<unk>\", filters='\"#$%&()*+-/=@[\\]^_`{|}~')\n",
        "output_tokenizer.fit_on_texts(tokenized_es)\n",
        "output_tokenizer.word_index[\"<pad>\"] = 0\n",
        "output_tokenizer.index_word[0] = \"<pad>\"\n",
        "\n",
        "# Get vocabulary sizes\n",
        "input_vocab_size = len(input_tokenizer.word_index)  # Add 1 for the padding token\n",
        "output_vocab_size = len(output_tokenizer.word_index)  # Add 1 for the padding token\n",
        "\n",
        "print(\"Input Vocabulary Size:\", input_vocab_size)\n",
        "print(\"Output Vocabulary Size:\", output_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r22jJqIC6FyJ",
        "outputId": "c35b0e85-6506-421f-e952-0b72af1441d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 1, 2, 3)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_tokenizer.word_index[\"<pad>\"], output_tokenizer.word_index[\"<unk>\"], output_tokenizer.word_index[\"<bos>\"], output_tokenizer.word_index[\"<eos>\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWaA72sWZDf8"
      },
      "source": [
        "## Keras translation model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pioqqZFFZF9k"
      },
      "source": [
        "Voy a intentar seguir un paso a paso de Keras para hacer un modelo seq2seq para traduccion\n",
        "\n",
        "https://keras.io/examples/nlp/neural_machine_translation_with_transformer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xo9tqqIKZRFH"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7829NVEa84L"
      },
      "source": [
        "### Parsing\n",
        "\n",
        "In this section we are adding SOS and EOS embedings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "eY1yS4OcyGAD",
        "outputId": "f937fc08-219b-4d9a-9fd8-42c38949259e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d615015a-4854-45e7-959e-cfddb05a7aac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7964</th>\n",
              "      <td>4 —chi iskai nuka kachaskakunaka kai alpata ma...</td>\n",
              "      <td>&lt;bos&gt; 4 ellos son los dos olivos y los dos can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2491</th>\n",
              "      <td>32 mana pudingasina kawaspaka chi sug mandag *...</td>\n",
              "      <td>&lt;bos&gt; 32 de otra manera cuando el otro rey est...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6704</th>\n",
              "      <td>3 iaia jesús ima rurangapa niska chasami kanga...</td>\n",
              "      <td>&lt;bos&gt; 3 pero fiel es el señor que os establece...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1552</th>\n",
              "      <td>18 jesús chasa rimaskataka iaia sasirdutikuna ...</td>\n",
              "      <td>&lt;bos&gt; 18 lo oyeron los principales sacerdotes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4429</th>\n",
              "      <td>3 pabloka munakurkami timoteoka nukawa purigri...</td>\n",
              "      <td>&lt;bos&gt; 3 pablo quiso que éste fuera con él y to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d615015a-4854-45e7-959e-cfddb05a7aac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d615015a-4854-45e7-959e-cfddb05a7aac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d615015a-4854-45e7-959e-cfddb05a7aac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e3757431-cfc0-4c99-a2cd-f498f4fe24fc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3757431-cfc0-4c99-a2cd-f498f4fe24fc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e3757431-cfc0-4c99-a2cd-f498f4fe24fc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 source  \\\n",
              "7964  4 —chi iskai nuka kachaskakunaka kai alpata ma...   \n",
              "2491  32 mana pudingasina kawaspaka chi sug mandag *...   \n",
              "6704  3 iaia jesús ima rurangapa niska chasami kanga...   \n",
              "1552  18 jesús chasa rimaskataka iaia sasirdutikuna ...   \n",
              "4429  3 pabloka munakurkami timoteoka nukawa purigri...   \n",
              "\n",
              "                                                 target  \n",
              "7964  <bos> 4 ellos son los dos olivos y los dos can...  \n",
              "2491  <bos> 32 de otra manera cuando el otro rey est...  \n",
              "6704  <bos> 3 pero fiel es el señor que os establece...  \n",
              "1552  <bos> 18 lo oyeron los principales sacerdotes ...  \n",
              "4429  <bos> 3 pablo quiso que éste fuera con él y to...  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inzPvin6c2We"
      },
      "source": [
        "### Spliting trainning and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QZnl-S8c8xl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train, test = train_test_split(tokenized_df, test_size = 0.10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTvnFCaddGbh"
      },
      "source": [
        "### Vectorizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzDyrK8Ao0y_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"<\", \"\")\n",
        "strip_chars = strip_chars.replace(\">\", \"\")\n",
        "\n",
        "sequence_length = 20\n",
        "batch_size = 128\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "inb_vectorization = TextVectorization(\n",
        "    max_tokens=input_vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "es_vectorization = TextVectorization(\n",
        "    max_tokens=output_vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WobBFPN0aMAE",
        "outputId": "227fde32-4315-4e9c-ce12-39ab770ebea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ],
      "source": [
        "print(string.punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zQvFb5Fs6xY"
      },
      "outputs": [],
      "source": [
        "inb_vectorization.adapt(tokenized_df['source'].values)\n",
        "es_vectorization.adapt(tokenized_df['target'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD_5ywkPOMN_",
        "outputId": "9084911f-5479-4fc4-80b0-abd3c817841e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " '<eos>',\n",
              " '<bos>',\n",
              " 'de',\n",
              " 'y',\n",
              " 'que',\n",
              " 'a',\n",
              " 'la',\n",
              " 'el',\n",
              " 'en',\n",
              " 'los',\n",
              " 'no',\n",
              " 'por',\n",
              " 'se',\n",
              " 'para',\n",
              " 'le',\n",
              " '—',\n",
              " 'con',\n",
              " 'dios']"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "es_vectorization.get_vocabulary(include_special_tokens=True)[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idNw48_h9kRZ"
      },
      "source": [
        "Next we are going to format the data set so that we can pass it correctry to the encoder and decoder transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sfv0t5l9e7D"
      },
      "outputs": [],
      "source": [
        "def format_dataset(ing, spa):\n",
        "\n",
        "    inb = inb_vectorization(ing)\n",
        "    es = es_vectorization(spa)\n",
        "\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": inb,\n",
        "            \"decoder_inputs\": es[:, :-1],\n",
        "        },\n",
        "        es[:, 1:],\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    ing_texts = pairs['source'].values\n",
        "    spa_texts = pairs['target'].values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((ing_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.cache().shuffle(2048).prefetch(16)\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train)\n",
        "test_ds = make_dataset(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz2dep53ILyz",
        "outputId": "0ba35047-e1c8-47d0-ba91-58e0f89abd34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (128, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (128, 20)\n",
            "targets.shape: (128, 20)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pPzyYedJW0m"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geN7PIl2JfXO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        attention_output = self.attention(query=inputs, value=inputs, key=inputs)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"dense_dim\": self.dense_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6kAtCyIJijA"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K376gaRbJYYZ"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_3 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.layernorm_4 = layers.LayerNormalization()\n",
        "        self.add = layers.Add()  # instead of `+` to preserve mask\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, use_causal_mask=True\n",
        "        )\n",
        "        out_1 = self.layernorm_1(self.add([inputs, attention_output_1]))\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1, value=out_1, key=out_1, use_causal_mask=True\n",
        "        )\n",
        "        out_2 = self.layernorm_2(self.add([out_1, attention_output_2]))\n",
        "\n",
        "        attention_output_3 = self.attention_3(\n",
        "            query=out_2, value=encoder_outputs, key=encoder_outputs\n",
        "        )\n",
        "        out_3 = self.layernorm_3(self.add([out_2, attention_output_3]))\n",
        "\n",
        "        proj_output = self.dense_proj(out_3)\n",
        "        return self.layernorm_4(self.add([out_3, proj_output]))\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"latent_dim\": self.latent_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x08kGOQDJoTl"
      },
      "source": [
        "Next, we assemble the end-to-end model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Io4wIsIAJpMH"
      },
      "outputs": [],
      "source": [
        "embed_dim = 512\n",
        "latent_dim = 512\n",
        "num_heads = 8\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, input_vocab_size, embed_dim)(encoder_inputs)\n",
        "for _ in range(6):  # Stack the TransformerEncoder layer 6 times\n",
        "    x = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder_outputs = x\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, output_vocab_size, embed_dim)(decoder_inputs)\n",
        "for _ in range(6):  # Stack the TransformerDecoder layer 6 times\n",
        "    x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "decoder_outputs = layers.Dense(output_vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "# Transformer\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Puj8hj1FJ5rB"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmxY7UtwJ_oo",
        "outputId": "3bab9fcd-4f0b-40a5-ae83-48f438e02488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " positional_embedding_4 (Po  (None, None, 512)            9563648   ['encoder_inputs[0][0]']      \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " transformer_encoder_2 (Tra  (None, None, 512)            8928768   ['positional_embedding_4[0][0]\n",
            " nsformerEncoder)                                                   ']                            \n",
            "                                                                                                  \n",
            " model_5 (Functional)        (None, None, 11816)          3785527   ['decoder_inputs[0][0]',      \n",
            "                                                          2          'transformer_encoder_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 56347688 (214.95 MB)\n",
            "Trainable params: 56347688 (214.95 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/15\n",
            "58/58 [==============================] - 25s 327ms/step - loss: 6.1044 - accuracy: 0.0999 - val_loss: 5.3976 - val_accuracy: 0.1486\n",
            "Epoch 2/15\n",
            "58/58 [==============================] - 15s 264ms/step - loss: 5.2110 - accuracy: 0.1539 - val_loss: 5.1070 - val_accuracy: 0.1691\n",
            "Epoch 3/15\n",
            "58/58 [==============================] - 16s 275ms/step - loss: 4.7989 - accuracy: 0.1796 - val_loss: 4.9795 - val_accuracy: 0.1835\n",
            "Epoch 4/15\n",
            "58/58 [==============================] - 16s 271ms/step - loss: 4.5396 - accuracy: 0.1960 - val_loss: 4.8936 - val_accuracy: 0.1847\n",
            "Epoch 5/15\n",
            "58/58 [==============================] - 15s 261ms/step - loss: 4.2889 - accuracy: 0.2181 - val_loss: 4.8015 - val_accuracy: 0.2225\n",
            "Epoch 6/15\n",
            "58/58 [==============================] - 15s 265ms/step - loss: 4.5184 - accuracy: 0.2291 - val_loss: 4.5658 - val_accuracy: 0.2473\n",
            "Epoch 7/15\n",
            "58/58 [==============================] - 15s 268ms/step - loss: 4.0864 - accuracy: 0.2586 - val_loss: 4.5408 - val_accuracy: 0.2459\n",
            "Epoch 8/15\n",
            "58/58 [==============================] - 16s 279ms/step - loss: 3.5401 - accuracy: 0.3157 - val_loss: 4.5433 - val_accuracy: 0.2484\n",
            "Epoch 9/15\n",
            "58/58 [==============================] - 16s 276ms/step - loss: 3.3178 - accuracy: 0.3370 - val_loss: 4.5355 - val_accuracy: 0.2688\n",
            "Epoch 10/15\n",
            "58/58 [==============================] - 15s 264ms/step - loss: 3.0941 - accuracy: 0.3646 - val_loss: 4.4908 - val_accuracy: 0.2669\n",
            "Epoch 11/15\n",
            "58/58 [==============================] - 15s 266ms/step - loss: 2.8941 - accuracy: 0.3895 - val_loss: 4.4211 - val_accuracy: 0.2788\n",
            "Epoch 12/15\n",
            "58/58 [==============================] - 15s 264ms/step - loss: 2.7945 - accuracy: 0.4046 - val_loss: 4.5037 - val_accuracy: 0.2736\n",
            "Epoch 13/15\n",
            "58/58 [==============================] - 16s 270ms/step - loss: 2.4897 - accuracy: 0.4465 - val_loss: 4.6173 - val_accuracy: 0.2716\n",
            "Epoch 14/15\n",
            "58/58 [==============================] - 16s 268ms/step - loss: 2.4756 - accuracy: 0.4556 - val_loss: 4.9174 - val_accuracy: 0.2636\n",
            "Epoch 15/15\n",
            "58/58 [==============================] - 15s 265ms/step - loss: 2.1281 - accuracy: 0.5054 - val_loss: 4.6357 - val_accuracy: 0.2907\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79bb10a22cb0>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs = 15  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQC5DJRaLO_z"
      },
      "source": [
        "## Decoding test sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhRfocIqLOuL"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "spa_vocab = es_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = inb_vectorization([input_sentence])\n",
        "    decoded_sentence = \"<bos>\"\n",
        "    for i in range(max_decoded_sentence_length-1):\n",
        "        tokenized_target_sentence = es_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"<eos>\":\n",
        "            break\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X48-dl-crF3B",
        "outputId": "02c26738-54f0-4c17-8571-d6c04398de56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21 chi jiru ruraskamanda ¿imatak chaskirkangichi chasa ruraskakunamandaka kunaura kamkunata iapa pingaipami iuiachiku chasa ruragkunaka wañuillami chaskinkuna\n",
            "<bos> 21 qué pues qué es decir que es la carne os parece que os haga dignos de la carne\n",
            "-------------------------\n",
            "16 *chiwanka chi iskai chunga chusku iacha taita kuna taita diuspa ñawi ladu mandadirupi tianakugka suma *kumurispa paita kungurirkakuna\n",
            "<bos> 16 y se levantaron los veinticuatro ancianos y los ancianos se pusieron de los que estaban de los que\n",
            "-------------------------\n",
            "26 ikuti suma luarpi tiaska jerusalén puiblumanda kagkunaka niraianmi ñi pita mana randiskakuna kagta chi puiblu nukanchipa mamasinami niraiá\n",
            "<bos> 26 pero la creación que es la carne es la carne ni la sangre de los hombres <eos>\n",
            "-------------------------\n",
            "13 kasapasmi tukugsamunkuna killa wangu tukuspa wasi wasillami puringapa munankuna mana killa wangulla tukunkunachu chankualkuna tukuspa tukuipi rimarispami purinkuna imasa mana chaiaska parlukuna wasa rimaikuna rimaspallami purinkuna\n",
            "<bos> 13 y si no se casa no se casa de qué hacéis bien y si no se ha de\n",
            "-------------------------\n",
            "3 sug judiukuna paipa rimaita mana uiangapa munagpikunaka chika ¿imatak niraiá ¿niraianchu taita dius kikin pai ima rurangapa niskata sakingapa kagta\n",
            "<bos> 3 porque es necesario que también los que se han sido hechos de la palabra de dios <eos>\n",
            "-------------------------\n",
            "15 maikanpa suti kaugsangapa willaraiaska librupi mana taririgpika paikunatapasmi chi ukuma sitai tukungapa kankuna sug luar i kai alpa luar musu kaskamanda\n",
            "<bos> 15 porque si el que se ha venido a la luz de la carne y el que no es\n",
            "-------------------------\n",
            "25 chasapika taita dius nirka jesucristo wañuchii tukuspa paipa iawar ichariskawa nukanchipa pandariikunata anchuchingapa paiwa suma iuiarigmandami pasinsiai tukurkanchi ñugpamanda maituku pandarii ruragpikunapas taita dius nukanchimanda iapami llakii iukarka chasawami tukui chi pandariikunata kungarirka chasaka jesucristo wañuskawami kawachirka pai imapipas imasa chaiaskasina allilla rurakugta\n",
            "<bos> 25 como él le dijo dios ha puesto como a la fe a la fe en la fe en\n",
            "-------------------------\n",
            "10 chasa kawaspaka chi iskandi katiraiagkuna kikinpa wasima *kutirkakuna maría magdalenata jesús kawariskamanda\n",
            "<bos> 10 cuando los discípulos se volvió a la mesa y se acercó e hicieron con él <eos>\n",
            "-------------------------\n",
            "25 ña asutingapa wataska charina kuura pabloka chipi saia kuska kapitanta tapurka —kamkunapa willaraiaskapi ¿allillachu ka romamanda runata asutingapa manara imapas tapuchispalla\n",
            "<bos> 25 cuando vio a la verdad que había pasado la puerta de la puerta de la multitud le seguía\n",
            "-------------------------\n",
            "7 chiuramandaka sug luarpi makanakuimi tiarka atun anjil miguel suti paipa anjilkunawa amarun kuku i amarunpa anjilkunawapasmi makanakurka chi amarunka paipa anjilkunawanta\n",
            "<bos> 7 y miré y he aquí un hombre ha puesto que se llama de un hombre y se ha\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "test_ing_texts = tokenized_df['source'].values\n",
        "for _ in range(10):\n",
        "    input_sentence = random.choice(test_ing_texts)\n",
        "    print(input_sentence)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(translated)\n",
        "    print(\"-------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9_xRpdirHyE"
      },
      "source": [
        "## Calculating BLEU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s70mINK1cxV"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for i in range(0,len(test['target'].values)):\n",
        "  data.append((test.iloc[i]['source'], test.iloc[i]['target']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbj-gAeVrHSv"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def calculate_bleu_score(data):\n",
        "    predicted_sentences = []\n",
        "    actual_sentences = []\n",
        "\n",
        "    for source_sentence, target_sentence in data:\n",
        "        # Generate prediction\n",
        "        predicted_seq = decode_sequence(source_sentence)\n",
        "\n",
        "        # Store predictions and actual sentences\n",
        "        predicted_sentences.append(predicted_seq.split())\n",
        "        actual_sentences.append([target_sentence.split()])\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    bleu_score = corpus_bleu(actual_sentences, predicted_sentences)\n",
        "    return bleu_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1apq-R32Z0m"
      },
      "outputs": [],
      "source": [
        "bleu_score = calculate_bleu_score(data)\n",
        "print(\"BLEU Score:\", bleu_score)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
